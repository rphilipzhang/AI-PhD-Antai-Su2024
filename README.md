# Artificial Intelligence for Business Research @Antai (Summer 2024)

## Teaching Team

* *Instructor*: <a href="https://rphilipzhang.github.io/rphilipzhang/index.html" target="_blank">Renyu (Philip) Zhang</a>, Associate Professor, Department of Decisions, Operations and Technology, CUHK Business School, philipzhang@cuhk.edu.hk.
* *Teaching Assistant*: Zhenkang Peng, PhD Candidate, Management Science and Engineering, SJTU Antai College of Economics and Management, zhenkang1397@gmail.com.

## Basic Information

- Website: https://github.com/rphilipzhang/AI-PhD-Antai-Su2024
- Time: 
   - **1st-Half**: May 8 (2:00PM-5:40PM); May 10 (6:00PM-9:05PM); May 11 (6:00PM-9:05PM); May 12 (2:00PM-5:40PM)
   - **2nd-Half**: May 15 (2:00PM-5:40PM); May 16 (6:00PM-9:05PM); May 17 (6:00PM-9:05PM); May 18 (2:00PM-5:40PM)
- Location: Xinshangyuan (æ–°ä¸Šé™¢) S303

## About
Welcome to the mono-repo of the PhD course AI for Business Research at SJTU Antai College of Economics and Management in Summer 2024. You may download the [Syllabus](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/AI-PhD-Syllabus-Su2024.pdf) of this course first. The purpose of this course is to learn the following:

- Have a basic understanding of the fundamental concepts/methods in machine learning (ML) and artificial intelligence (AI) that are used (or potentially useful) in business research.
- Understand how business researchers have utilized ML/AI and what managerial questions have been addressed by ML/AI in the recent decade.
- Nurture a taste of what the state-of-the-art AI/ML technologies can do in the ML/AI community and, potentially, in your own research field.

We will meet at the time specified above in Xinshangyuan (æ–°ä¸Šé™¢) S303. Please ask for my approval if you need to join us via the following Zoom Meeting link:

- [Zoom Meeting link](https://cuhk.zoom.us/j/92669380190?pwd=YWJXRTIwSmdVNEEzc0RqWk4rdUIxQT09), Meeting ID 926 6938 0190, Passcode 869709. 

Most of the code in this course will be distributed through the [Google CoLab](https://colab.research.google.com/) cloud computing environment to avoid the incompatibility and version control issues on your local individual computer. On the other hand, you can always download the Jupyter Notebook from CoLab and run it your own computer.

- The **CoLab** files of this course can be found at [this folder](https://drive.google.com/drive/folders/1CF1Xu4oJXFFNhjSoMNVZGbhNjT3wdAq9?usp=sharing).
- The **Google Sheet** to sign up for groups and group tasks can be found [here](https://docs.google.com/spreadsheets/d/127rkG4QN_85JNQce9g3egzby9c72Yk0kRZqfUE7QfYA/edit?usp=sharing).

If you have any feedback on this course, please directly contact Philip at philipzhang@cuhk.edu.hk and we will try our best to address it.

## Brief Schedule

|Session|Date & Time|Topic|Key Words|
|:-------:|:-------------:|:----:|:-:|
|1|May 8, 2:00pm-5:40pm|AI/ML in a Nutshell|Course Intro, ML Models, DL|
|2|May 10, 6:00pm-9:05pm|Prediction and Traditional NLP|Prediction in Biz Research, Pre-processing, $N$-gram, NaÃ¯ve Bayes| 
|3|May 11, 6:00pm-9:05pm|NLP (II): Deep Learning|Word2Vec, RNN, Seq2Seq, Attention, Transformer|
|4|May 12, 2:00pm-5:40pm|NLP (III): LLM|BERT, GPT, Emergent Abilities, Chain-of-Thought, In-context Learning, GenAI in Business Research|
|5|May 15, 2:00pm-5:40pm|CV (I): Image Classification|CNN, AlexNet, ResNet, ViT|
|6|May 16, 6:00pm-9:05pm|CV (II): Image Segmentation and Video Analysis|R-CNN, YOLO, 3D-CNN|
|7|May 17, 6:00pm-9:05pm|Unsupervised Learning (I): Clustering & Topic Modeling|GMM, EM Algorithm, LDA|
|8|May 18, 2:00pm-5:40pm|Unsupervised Learning (II): Diffusion Models|VAE, DDPM, LDM, DiT|


## Important Dates


|Date| Time|Event|Note|
|:--:|:-:|:---:|:--:|
|May 8| 11:59pm|[Group Sign-Ups](https://docs.google.com/spreadsheets/d/127rkG4QN_85JNQce9g3egzby9c72Yk0kRZqfUE7QfYA/edit#gid=0)|Each group has at most two students.|
|May 9| 10:00am-noon|Online Python Tutorial|Given by Zhenkang Peng, [Python Tutorial CoLab](https://colab.research.google.com/drive/1Eygkyl-L1wziIHM8Ww64WMEBdWpyyvnk?usp=sharing), [Zoom Link](https://cuhk.zoom.us/j/93652436720?pwd=UE04RkNjd1NsckNwSnlpVHB3WjQxdz09)|
|May 10| 10:00am-noon|Online [PyTorch](https://pytorch.org/docs/stable/nn.html) Tutorial|Given by Zhenkang Peng, [PyTorch Tutorial CoLab](https://colab.research.google.com/drive/1eR9XVw46Z1kV1c1kexBP6Si-3v4bQ5Cn?usp=sharing), [Zoom Link](https://cuhk.zoom.us/j/93652436720?pwd=UE04RkNjd1NsckNwSnlpVHB3WjQxdz09)|
|May 13|11:59pm|[Project 1 Choice Due](https://docs.google.com/spreadsheets/d/127rkG4QN_85JNQce9g3egzby9c72Yk0kRZqfUE7QfYA/edit#gid=902044646)||
|May 19|11:59pm|[Project 2 Choice Due](https://docs.google.com/spreadsheets/d/127rkG4QN_85JNQce9g3egzby9c72Yk0kRZqfUE7QfYA/edit#gid=674416022)||
|June 2|11:59pm|[All Problem Sets and Projects Due](https://docs.google.com/spreadsheets/d/127rkG4QN_85JNQce9g3egzby9c72Yk0kRZqfUE7QfYA/edit?usp=sharing)|Project Report page limit: 5 each| 


## Replication Projects

Choose one from the following to replicate for **Project 1 (1st-Half)**:
- Chen, Luyang, Markus Pelger, Jason Zhu (2023) Deep Learning in Asset Pricing. *Management Science* 70(2):714-750. [Link to the Paper](https://pubsonline.informs.org/doi/full/10.1287/mnsc.2023.4695); [Link to the GitHub Repo](https://github.com/LouisChen1992/Deep_Learning_in_Asset_Pricing).
- Mei, Q., Xie, Y., Yuan, W., Jackson, M. O. (2024). A Turing test of whether AI chatbots are behaviorally similar to humans. *Proceedings of the National Academy of Sciences*, 121(9), e2313925121. [Link to the Paper](https://www.pnas.org/doi/full/10.1073/pnas.2313925121); [Link to the GitHun Repo](https://github.com/yutxie/ChatGPT-Behavioral).

Choose one from the following to replicate for **Project 2 (2nd-Half)**:
- Zhang, Mengxia and Lan Luo. 2023. Can consumer-posted photos serve as a leading indicator of restaurant survival? Evidence from Yelp. *Management Science* 69(1): 25-50. [Link to the Paper](https://pubsonline.informs.org/doi/full/10.1287/mnsc.2022.4359); [Link to the Data and Code](https://www.dropbox.com/s/r53aill2dkbu3ir/management_science_data_code_submission.zip).
- Burnap, Alex , John R. Hauser, Artem Timoshenko (2023) Product Aesthetic Design: A Machine Learning Augmentation. *Marketing Science* 42(6):1029-1056. [Link to the Paper](https://pubsonline.informs.org/doi/full/10.1287/mksc.2022.1429); [Link to Download the Replication Files](https://services.informs.org/dataset/mksc/download.php?doi=mksc.2022.1429).



## Useful Resources
Find more on the [Syllabus](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/AI-PhD-Syllabus-Su2024.pdf).

- **Books**: [ESL](https://hastie.su.domains/ElemStatLearn/), [Deep Learning](https://www.deeplearningbook.org/), [Dive into Deep Learning](https://d2l.ai/), [ML Fairness](https://fairmlbook.org/), [Applied Causal Inference Powered by ML and AI](https://causalml-book.org/)
- **Courses**: [ML Intro by Andrew Ng](https://www.coursera.org/specializations/machine-learning-introduction), [DL Intro by Andrew Ng](https://www.coursera.org/specializations/deep-learning), [NLP (CS224N) by Chris Manning](https://web.stanford.edu/class/cs224n/), [CV (CS231N) by Fei-Fei Li](http://cs231n.stanford.edu/), [Deep Unsupervised Learning by Pieter Abbeel](https://sites.google.com/view/berkeley-cs294-158-sp24/home), [DLR by Sergey Levine](https://rail.eecs.berkeley.edu/deeprlcourse/), [DL Theory by Matus Telgarsky](https://mjt.cs.illinois.edu/courses/dlt-f22/), [LLM by Danqi Chen](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/), [Generative AI by Andrew Ng](https://www.deeplearning.ai/short-courses/), [Machine Learning and Big Data by Melissa Dell and Matthew Harding](https://www.aeaweb.org/conference/cont-ed/2023-webcasts), [Digital Economics and the Economics of AI by Martin Beraja, Chiara Farronato, Avi Goldfarb, and Catherine Tucker](https://www.aeaweb.org/content/file?id=19707)

## Detailed Schedule

The following schedule is tentative and subject to changes.

### First-Half (May/08/2024-May/12/2024) 

### Session 1. Artificial Intelligence and Machine Learning in a Nutshell (May/08/2024, 2:00pm-5:40pm)

- **Keywords**: Course Introduction, Traditional Machine Learning Methods, Bias-Variance Trade-off, Cross Validation, Deep Learning Basics, Neural Nets Models, Computational Issues of Deep Learning
- **Slides**: [Course Introduction](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-1-Intro.pdf), [Machine Learning Basics](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-2-Intro2ML.pdf), [Deep Learning Basics](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-3-Intro2DL.pdf)
- **CoLab Notebook Demos**: [Traditional ML Models: kNN, Decision Trees, Random Forests, XGBT](https://drive.google.com/drive/u/0/folders/1yBV9xT8aJTBqeQTGWv3kgMYXcj_BzUfQ), [Deep Learning: Gradient Descent, Chain Rule, Initialization, Dropout, Micro-Gradient](https://drive.google.com/drive/u/0/folders/1IfqlTOPGg5rFghxCjgNxXVQ23i-1MnJS)
- **Homework**: [Problem Set 1 - Bias-Variance Trade-Off](https://colab.research.google.com/drive/1-KfKoggMgFlimnelDD6CR1cROb2gfYnc)
- **Online Python Tutorial**: [Python Tutorial CoLab](https://colab.research.google.com/drive/1Eygkyl-L1wziIHM8Ww64WMEBdWpyyvnk?usp=sharing), 10:00am-noon, May/09/2024 (Thursday), given by Zhenkang Peng, zhenkang1397@gmail.com. [Zoom Meeting Link](https://cuhk.zoom.us/j/93652436720?pwd=UE04RkNjd1NsckNwSnlpVHB3WjQxdz09), Meeting ID: 936 5243 6720, Passcode: 234990
- **Online PyTorch Tutorial**: [PyTorch Tutorial CoLab](https://colab.research.google.com/drive/1eR9XVw46Z1kV1c1kexBP6Si-3v4bQ5Cn?usp=sharing), 10:00am-noon, May/10/2024 (Friday), given by Zhenkang Peng, zhenkang1397@gmail.com. [Zoom Meeting Link](https://cuhk.zoom.us/j/93652436720?pwd=UE04RkNjd1NsckNwSnlpVHB3WjQxdz09), Meeting ID: 936 5243 6720, Passcode: 234990
- **References**:
    - *The Elements of Statistical Learning* (2nd Edition), 2009, by Trevor Hastie, Robert Tibshirani, Jerome Friedman. [Link to the Book](https://hastie.su.domains/ElemStatLearn/).
    - *Probabilistic Machine Learning: An Introduction*, 2022, by Kevin Murphy. [Link to the Book](https://probml.github.io/pml-book/book1.html).
    - Mullainathan, Sendhil, and Jann Spiess. 2017. Machine learning: an applied econometric approach. *Journal of Economic Perspectives* 31(2): 87-106.
    - Athey, Susan, and Guido W. Imbens. 2019. Machine learning methods that economists should know about. *Annual Review of Economics* 11: 685-725.
    - Hofman, Jake M., et al. 2021. Integrating explanation and prediction in computational social science. *Nature* 595.7866: 181-188.
    - Bastani, Hamsa, Dennis Zhang, and Heng Zhang. 2022. Applied machine learning in operations management. *Innovative Technology at the Interface of Finance and Operations*. Springer: 189-222.
    - Kelly, Brian, and Dacheng Xiu. 2023. Financial machine learning, *SSRN*, [link to the paper](https://ssrn.com/abstract=4501707).   
    - [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html), by Rich Sutton, which develops so far the most critical insight of AI: "The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin."
    - *Deep Learning*, 2016, by Ian Goodfellow, Yoshua Bengio and Aaron Courville, https://www.deeplearningbook.org/.
    - *Dive into Deep Learning* (2nd Edition), 2023, by Aston Zhang, Zack Lipton, Mu Li, and Alex J. Smola. [Link to the Book](https://d2l.ai/).
    - *Probabilistic Machine Learning: Advanced Topics*, 2023, by Kevin Murphy. [Link to the Book](https://probml.github.io/pml-book/book2.html).
    - *Deep Learning with PyTorch*, 2020, by Eli Stevens, Luca Antiga, and Thomas Viehmann.
    - Gu, Shihao, Brian Kelly, and Dacheng Xiu. 2020. Empirical asset pricing with machine learning. *Review of Financial Studies* 33: 2223-2273.
    - [GPU Comparisons](https://bizon-tech.com/gpu-benchmarks/NVIDIA-A100-80-GB-(PCIe)-vs-NVIDIA-H100-(PCIe)-vs-NVIDIA-RTX-6000-Ada/624vs632vs640)
    - [GitHub Repo for Micrograd](https://github.com/karpathy/micrograd), by [Andrej Karpathy](https://github.com/karpathy).
    - [Parameter Initialization and Batch Normalization (in Chinese)](https://zhuanlan.zhihu.com/p/25110150).


### Session 2. Predictions in Business Research and Traditonal NLP (May/10/2024, 6:00pm-9:05pm)
- **Keywords**: Prediction Problems in Business Research, Pre-processing and Word Representations in Traditional Natural Language Processing, N-Gram, NaÃ¯ve Bayes, Traditional NLP Applied to Business/Econ Research
- **Slides**: [Prediction Problems in Business Research](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-4-Prediction.pdf), [NLP(I): Traditional NLP](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-5-NLP(I).pdf)
- **CoLab Notebook Demos**: [NLP Pre-processing](https://colab.research.google.com/drive/1DM8HGhe4yAiku0GyenRmw_m7ApZw0pEh), [N-Gram](https://colab.research.google.com/drive/1jQGDTL3yYBtiX9Z3ymoFh-uJ0491ssFn), [NaÃ¯ve Bayes](https://colab.research.google.com/drive/1ayQuYLglKqgheoAzWJiKnxtclpl_A0eN)
- **References**:
    - Kleinberg, Jon, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. 2015. Prediction policy problems. *American Economic Review* 105(5): 491-495.
    - Mullainathan, Sendhil, and Jann Spiess. 2017. Machine learning: an applied econometric approach. *Journal of Economic Perspectives* 31(2): 87-106.
    - Kleinberg, Jon, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. 2018. Human decisions and machine predictions. *Quarterly Journal of Economics* 133(1): 237-293.
    - Bajari, Patrick, Denis Nekipelov, Stephen P. Ryan, and Miaoyu Yang. 2015. Machine learning methods for demand estimation. *American Economic Review*, 105(5): 481-485.
    - Farias, Vivek F., and Andrew A. Li. 2019. Learning preferences with side information. *Management Science* 65(7): 3131-3149.
    - Cui, Ruomeng, Santiago Gallino, Antonio Moreno, and Dennis J. Zhang. 2018. The operational value of social media information. *Production and Operations Management*, 27(10): 1749-1769.
    - Gentzkow, Matthew, Bryan Kelly, and Matt Taddy. 2019. Text as data. *Journal of Economic Literature*, 57(3): 535-574.
    - Hansen, Stephen, Michael McMahon, and Andrea Prat. 2018. Transparency and deliberation within the FOMC: A computational linguistics approach. *Quarterly Journal of Economics*, 133(2): 801-870.
    - Tetlock, Paul. 2007. Giving content to investor sentiment: The role of media in the stock market. *Journal of Finance*, 62(3): 1139-1168.
    - Baker, Scott, Nicholas Bloom, and Steven Davis, 2016. Measuring economic policy uncertainty. *Quarterly Journal of Economics*, 131(4): 1593-1636.
    - Gentzkow, Matthew, and Jesse Shapiro. 2010. What drives media slant? Evidence from US daily newspapers. *Econometrica*, 78(1): 35-71.
    - Chapter 2, 12, & 13 *Introduction to Information Retrieval*, 2008, Cambridge University Press, by Christopher D. Manning, Prabhakar Raghavan and Hinrich Schutze. [Link to the Book](https://nlp.stanford.edu/IR-book/information-retrieval-book.html).
    - Chapter 2, 3, & 4, *Speech and Language Processing* (3rd ed. draft), 2023, by Dan Jurafsky and James H. Martin. [Link to the Book](https://web.stanford.edu/~jurafsky/slp3/). 
    - [Natural Language Tool Kit (NLTK) Documentation](https://www.nltk.org/)

### Session 3. Deep-Learning-Based NLP: From Word2Vec to Transformers (May/11/2024, 6:00pm-9:05pm)
- **Keywords**: Word2Vec: Continuous Bag of Words and Skip-Gram, RNN, LSTM, Seq2Seq, Attention Mechanism, Transformer
- **Slides**: [NLP(II): Deep Learning Based NLP](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-6-NLP(II).pdf)
- **CoLab Notebook Demos**: [Word2Vec: CBOW](https://colab.research.google.com/drive/17TH1pNWhNKnWG0H58XL2yxGu17xYvJ2x), [Word2Vec: Skip-Gram](https://colab.research.google.com/drive/18EJDphTR-YM1rCnjixq6CFwON-lqQp4G), [RNN & LSTM](https://colab.research.google.com/drive/1yhg2tO0-cJvQETT2MXZalwRzesqaPlJL), [Attention Mechanism](https://colab.research.google.com/drive/1u1xz4ja_CkTS7UN4PSqT2qOelJJdi24u), [Transformer](https://colab.research.google.com/drive/1MKRzM0Ql_2PFplsZ_Q-PL7vS21YCfkKz)
- **Homework**: [Problem Set 2 - Word2Vec & LSTM for Sentiment Analysis](https://colab.research.google.com/drive/1A9BlvYJgjX-xZLWTbaMFA7XBv14BA65Z?usp=drive_link)
- **References**:
    - Ash, Elliot, and Stephen Hansen. 2023. Text algorithms in economics. *Annual Review of Economics*, 15: 659-688. [Associated GitHub with Code Demonstrations](https://github.com/sekhansen/text_algorithms_econ).
    - Timoshenko, Artem, and John R. Hauser. 2019. Identifying customer needs from user-generated content. *Marketing Science*, 38(1): 1-20.
    - Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeff Dean. 2013. Efficient estimation of word representations in vector space. *ArXiv Preprint*, arXiv:1301.3781.
    - Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. *Advances in Neural Information Processing Systems (NeurIPS)* 26.
    - Li, Kai, Feng Mai, Rui Shen, and Xinyan Yan. 2021. Measuring corporate culture using machine learning. *Review of Financial Studies*, 34(7): 3265-3315.
    - Chen, Fanglin, Xiao Liu, Davide Proserpio, and Isamar Troncoso. 2022. Product2Vec: Leveraging representation learning to model consumer product choice in large assortments. *Available at SSRN 3519358*.
    - Qi, Meng, Yuanyuan Shi, Yongzhi Qi, Chenxin Ma, Rong Yuan, Di Wu, Zuo-Jun (Max) Shen. 2023. A Practical End-to-End Inventory Management Model with Deep Learning. *Management Science*, 69(2): 759-773.
    - Sarzynska-Wawer, Justyna, Aleksander Wawer, Aleksandra Pawlak, Julia Szymanowska, Izabela Stefaniak, Michal Jarkiewicz, and Lukasz Okruszek. 2021. Detecting formal thought disorder by deep contextualized word representations. *Psychiatry Research*, 304, 114135.
    - Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural networks. *Advances in neural information processing systems*, 27.
    - Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. *ICLR*
    - Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... and Polosukhin, I. (2017). Attention is all you need. *Advances in neural information processing systems*, 30.
    - Parts 1, 2, 5, 6, and 8 Lecture Notes and Slides for CS224n: Natural Language Processing with Deep Learning, by Christopher D. Manning, Diyi Yang, and Tatsunori Hashimoto, https://web.stanford.edu/class/cs224n/.
    - Chapters 9, 10, and 11 *Dive into Deep Learning* (2nd Edition), 2023, by Aston Zhang, Zack Lipton, Mu Li, and Alex J. Smola, https://d2l.ai/.
    - [Word Embeddings Trained on Google News Corpus](https://github.com/mmihaltz/word2vec-GoogleNews-vectors)
    - [RNN and LSTM Visualizations](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
    - [PyTorch's Tutorial of Seq2Seq for Machine Translation](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)
    - [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
    - [Transformer from Scratch](https://peterbloem.nl/blog/transformers), with the [Code on GitHub](https://github.com/pbloem/former)

### Session 4. Deep-Learning-Based NLP: Pretraining and LLM (May/12/2024, 2:00pm-5:40pm)
- **Keywords**: BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pretrained Transformers), LLM (Large Language Model)
- **Slides**: [Deep Learning Computation](https://docs.google.com/presentation/d/1RlloczzRGrHOZqV_KBYVxYy7aljx4nN8BIEbx1KBWKE/edit?invite=CPjxzs8B#slide=id.g2c123b2306c_0_358), [Pretraining and LLM](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-7-NLP(III).pdf)
- **CoLab Notebook Demos**: [Crafting Intelligence: The Art of Deep Learning Modeling](https://colab.research.google.com/drive/1FoFSjfGiCiAXJCCogIE5f12FrN-k9nLh), [BERT API @ Hugging Face](https://colab.research.google.com/drive/1JR3aaNuIbEZ79EIm6Djc75yo0ZWXwxUV?usp=drive_link)
- **References**:
    - Devlin, Jacob, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2018. BERT: Pre-training of deep bidirectional transformers for language understanding. *ArXiv preprint* arXiv:1810.04805. [GitHub Repo](https://github.com/google-research/bert)
    - Radford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training, (GPT-1) [PDF link](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf), [GitHub Repo](https://github.com/openai/finetune-transformer-lm)
    - Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8), 9. (GPT-2) [PDF Link](https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf), [GitHub Repo](https://github.com/openai/gpt-2)
    - Brown, Tom, et al. 2020. Language models are few-shot learners. *Advances in neural information processing systems*, 33, 1877-1901. (GPT-3) [GitHub Repo](https://github.com/openai/gpt-3)
    - Huang, Allen H., Hui Wang, and Yi Yang. 2023. FinBERT: A large language model for extracting information from financial text. *Contemporary Accounting Research*, 40(2): 806-841. [GitHub Repo](https://github.com/yya518/FinBERT)
    - Wei, Jason, et al. 2021. Finetuned language models are zero-shot learners. *ArXiv preprint* arXiv:2109.01652, [link to the paper](https://arxiv.org/abs/2109.01652).
    - Wei, Jason, et al. 2022. Emergent abilities of large language models. *ArXiv preprint* arXiv:2206.07682, [link to the paper](https://arxiv.org/abs/2206.07682).
    - Ouyang, Long, et al. 2022. Training language models to follow instructions with human feedback. *Advances in Neural Information Processing Systems*, **35**, 27730-27744.
    - Wei, Jason, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. *Advances in Neural Information Processing Systems*, **35**, 24824-24837.
    - Kaplan, Jared. 2020. Scaling laws for neural language models. *ArXiv preprint* arXiv:2001.08361, [link to the paper](https://arxiv.org/abs/2001.08361).
    - Hoffmann, Jordan, et al. 2022. Training compute-optimal large language models. *ArXiv preprint* arXiv:2203.15556, [link to the paper](https://arxiv.org/abs/2203.15556).
    - Shinn, Noah, et al. 2023. Reflexion: Language agents with verbal reinforcement learning. *ArXiv preprint* arXiv:2303.11366, [link to the paper](https://arxiv.org/abs/2303.11366).
    - Reisenbichler, Martin, Thomas Reutterer, David A. Schweidel, and Daniel Dan. 2022. Frontiers: Supporting content marketing with natural language generation. *Marketing Science*, **41**(3): 441-452.
    - Romera-Paredes, B., Barekatain, M., Novikov, A. et al. 2023. Mathematical discoveries from program search with large language models. *Nature*, [link to the paper](https://doi.org/10.1038/s41586-023-06924-6).
    - Parts 9 & 10, Lecture Notes and Slides for CS 224N: Natural Language Processing with Deep Learning, by Christopher D. Manning, Diyi Yang, and Tatsunori Hashimoto. [Link to CS 224N](https://web.stanford.edu/class/cs224n/)
    - COS 597G: Understanding Large Language Models, by Danqi Chen. [Link to COS 597G](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)
    - [A Visual Guide to BERT](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/), [How GPT-3 Works](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)
    - [Andrej Karpathy's 1-hour Talk on LLM](https://www.youtube.com/watch?v=zjkBMFhNj_g)
    - [CS224n, Hugging Face Tutorial](https://colab.research.google.com/drive/13r94i6Fh4oYf-eJRSi7S_y_cen5NYkBm?usp=sharing


### Second-Half (May/15/2024-May/18/2024) 


### Session 5. Deep-Learning-Based CV: Image Classification (May/15/2024, 2:00pm-5:40pm)
- **Keywords**: Large Language Models Applications, Convolution Neural Nets (CNN), LeNet, AlexNet, VGG, ResNet, ViT
- **Slides**: [Image Classification](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-8-CV(I).pdf)
- **CoLab Notebook Demos**: [CNN, LeNet, & AlexNet](https://colab.research.google.com/drive/175Zl-yJ0T9PpvphjYsGgVkISBVSOpk87), [VGG](https://colab.research.google.com/drive/1PBaCRzhKGErQd9wbvoMrS1ZpOpZtqpMe), [ResNet](https://colab.research.google.com/drive/12uHYuOg1yawBBuk0E0QdRtQfiK-qSjdD), [ViT](https://colab.research.google.com/drive/1rkGJwQ8bd_iwwnRsvMTzoOGp_S8XU_-J)
- **Homework**: [Problem Set 3 - AlexNet and ResNet](https://colab.research.google.com/drive/19q7qhYmPYbkQGEa12N2RWZRJXbzn5f30), due at 11:59pm, June 2, Sunday.
- **References**:
    - Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. 2012. Imagenet classification with deep convolutional neural networks. *Advances in Neural Information Processing Systems*, 25.
    - Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. *arXiv preprint arXiv:1409.1556*.
    - He, Kaiming, Xiangyu Zhang, Shaoqing Ren and Jian Sun. 2016. Deep residual learning for image recognition. *Proceedings of the IEEE conference on computer vision and pattern recognition*, 770-778.
    - Hu, J., Shen, L., & Sun, G. (2018). Squeeze-and-excitation networks. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 7132-7141).
    - Dosovitskiy, Alexey, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. *ArXiv preprint*, arXiv:2010.11929, [link to the paper](https://arxiv.org/abs/2010.11929), [link to the GitHub repo](https://github.com/google-research/vision_transformer).
    - Jean, Neal, Marshall Burke, Michael Xie, Matthew W. Davis, David B. Lobell, and Stefand Ermon. 2016. Combining satellite imagery and machine learning to predict poverty. *Science*, 353(6301), 790-794.
    - Zhang, Mengxia and Lan Luo. 2023. Can consumer-posted photos serve as a leading indicator of restaurant survival? Evidence from Yelp. *Management Science* 69(1): 25-50.
    - Zhang, S., Lee, D., Singh, P. V., & Srinivasan, K. (2022). What makes a good image? Airbnb demand analytics leveraging interpretable image features. *Management Science*, 68(8), 5644-5666.
    - Course Notes (Lectures 5 & 6) for CS231n: Deep Learning for Computer Vision, by Fei-Fei Li, Ruohan Gao, & Yunzhu Li. [Link to CS231n](http://cs231n.stanford.edu/schedule.html).
    - Chapters 7 and 8, *Dive into Deep Learning* (2nd Edition), 2023, by Aston Zhang, Zack Lipton, Mu Li, and Alex J. Smola. [Link to the book](https://d2l.ai/).
    - [Fine-Tune ViT for Image Classification with Hugging Face ðŸ¤— Transformers](https://huggingface.co/blog/fine-tune-vit) 
    - [Hugging Face ðŸ¤— ViT CoLab Tutorial](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/vit_image_classification_explained.ipynb)


### Session 6. Deep-Learning-Based CV (II): Object Detection & Video Analysis (May/16/2024, 6:00pm-9:05pm)
- **Keywords**: Image Processing Applications, Localization, R-CNNs, YOLOs, Semantic Segmentation, 3D CNN, Video Analysis Applications 
- **Slides**: [Object Detection and Video Analysis](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-9-CV(II).pdf) 
- **CoLab Notebook Demos**: [Data Augmentation](https://colab.research.google.com/drive/1aKJbGb_1lwKlBGJJhGg7y-W_H7f_QyQK?usp=share_link), [Faster R-CNN & YOLO v5](https://colab.research.google.com/drive/1bvFqFCJt-TtQOrmrsgIX3DTlBseyFlGQ?usp=share_link)
- **References**:
    - Girshick, R., Donahue, J., Darrell, T. and Malik, J., 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 580-587).
    - Girshick, R., Donahue, J., Darrell, T., & Malik, J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 580-587).
    - Girshick, R. (2015). Fast r-cnn. In *Proceedings of the IEEE international conference on computer vision* (pp. 1440-1448).
    - Ren, S., He, K., Girshick, R., & Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. *Advances in neural information processing systems*, 28.
    - Redmon, Joseph, Santosh Divvala, Ross Girshick, and Ali Farhadi. 2016. You only look once: Unified, real-time object detection. *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 779-788).
    - Long, J., Shelhamer, E., & Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 3431-3440).
    - Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R. and Fei-Fei, L., 2014. Large-scale video classification with convolutional neural networks. *Proceedings of the IEEE conference on Computer Vision and Pattern Recognition* (pp. 1725-1732).
    - Glaeser, Edward L., Scott D. Kominers, Michael Luca, and Nikhil Naik. 2018. Big data and big cities: The promises and limitations of improved measures of urban life. *Economic Inquiry*, **56**(1): 114-137.
    - Zhang, S., Xu, K. and Srinivasan, K., 2023. Frontiers: Unmasking Social Compliance Behavior During the Pandemic. *Marketing Science*, 42(3), pp.440-450.
    - Liu, Liu, Dzyabura, Daria, Mizik, Natalie. 2020. Visual listening in: Extracting brand image portrayed on social media. *Marketing Science*, **39**(4): 669-686. [Link to the Paper](https://pubsonline.informs.org/doi/10.1287/mksc.2020.1226)
    - Yang, Jeremy, Juanjuan Zhang, and Yuhan Zhang. 2023. Engagement that sells: Influencer video advertising on TikTok. *Available at SSRN* [Link to the Paper](https://ssrn.com/abstract=3815124)
    - Course Notes (Lectures 10 & 11) for CS231n: Deep Learning for Computer Vision, by Fei-Fei Li, Ruohan Gao, & Yunzhu Li. [Link to CS231n](http://cs231n.stanford.edu/schedule.html).
    - Chapter 14, *Dive into Deep Learning* (2nd Edition), 2023, by Aston Zhang, Zack Lipton, Mu Li, and Alex J. Smola. [Link to the book](https://d2l.ai/).  


### Session 7. Unsupervised Learning: Clustering, Topic Modeling & VAE (May/17/2024, 6:00pm-9:05pm)
- **Keywords**: K-Means, Gaussian Mixture Models, EM-Algorithm, Latent Dirichlet Allocation, Variational Auto-Encoder
- **Slides**: [Clustering, Topic Modeling & VAE](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-10-Unsupervised(I).pdf) 
- **CoLab Notebook Demos**: [K-Means](https://colab.research.google.com/drive/1b8_obXdx-0895V1kgjkMPV73EvriNa_Q?usp=drive_link), [LDA](https://colab.research.google.com/drive/1hjUR_6bXl2kaioM2DZdIjtKcm7QkAwzL?usp=drive_link), [VAE](https://colab.research.google.com/drive/1EUwZmAFnf_tP3BPg8VzlIAOOmqm7nB8h?usp=drive_link)
- **Homework**: [Problem Set 4 - Unsupervised Learning (EM & LDA)](https://colab.research.google.com/drive/1_tXPFCc-AHtLKzQGm6aD4B8EhVz9sX2l), due at 11:59pm, June 2, Sunday.
- **References**:
    - Blei, David M., Ng, Andrew Y., and Jordan, Michael I. 2003. Latent Dirichlet allocation. *Journal of Machine Learning Research*, 3(Jan): 993-1022.
    - Kingma, D.P. and Welling, M., 2013. Auto-encoding Variational Bayes. arXiv preprint *arXiv:1312.6114*.
    - Kingma, D.P. and Welling, M., 2019. An introduction to variational autoencoders. *Foundations and TrendsÂ® in Machine Learning*, 12(4), pp.307-392.
    - Bandiera, O., Prat, A., Hansen, S., & Sadun, R. 2020. CEO behavior and firm performance. *Journal of Political Economy*, 128(4), 1325-1369.
    - Liu, Jia and Olivier Toubia. 2018. A semantic approach for estimating consumer content preferences from online search queries. *Marketing Science*, 37(6): 930-952.   
    - Tirunillai, S., & Tellis, G. J. (2014). Mining marketing meaning from online chatter: Strategic brand analysis of big data using latent dirichlet allocation. *Journal of marketing research*, 51(4), 463-479. 
    - Mueller, Hannes, and Christopher Rauh. 2018. Reading between the lines: Prediction of political violence using newspaper text. *American Political Science Review*, 112(2): 358-375.
    - Tian, Z., Dew, R. and Iyengar, R., 2023. Mega or Micro? Influencer Selection Using Follower Elasticity. *Journal of Marketing Research*.
    - Chapters 8.5 and 14, *The Elements of Statistical Learning* (2nd Edition), 2009, by Trevor Hastie, Robert Tibshirani, Jerome Friedman, [Link to Book](https://hastie.su.domains/ElemStatLearn/).
    - Course Notes (Lectures 1 & 4) for CS294-158-SP24: Deep Unsupervised Learning, taught by Pieter Abbeel, Wilson Yan, Kevin Frans, Philipp Wu. [Link to CS294-158-SP24](https://sites.google.com/view/berkeley-cs294-158-sp24/home). 

### Session 8. Unsupervised Learning: Diffusion Models (May/18/2024, 2:00pm-5:40pm)
- **Keywords**: Denoised Diffusion Probabilistic Models, Latent Diffusion Models, CLIP, Imagen, Diffusion Transformers, Course Summary
- **Slides**: [Diffusion Models](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024/blob/main/Slides/AI-PhD-Su2024-11-Unsupervised(II).pdf), [Course Summary]() 
- **CoLab Notebook Demos**: [DDPM](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb), [DiT](https://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb)
- **References**:
    - Kingma, D.P. and Welling, M., 2013. Auto-encoding Variational Bayes. arXiv preprint *arXiv:1312.6114*.
    - Kingma, D.P. and Welling, M., 2019. An introduction to variational autoencoders. *Foundations and TrendsÂ® in Machine Learning*, 12(4), pp.307-392.
    - Ho, J., Jain, A. and Abbeel, P., 2020. Denoising diffusion probabilistic models. *Advances in neural information processing systems*, 33, 6840-6851.
    - Chan, S.H., 2024. Tutorial on Diffusion Models for Imaging and Vision. *arXiv preprint* arXiv:2403.18103.
    - Peebles, W. and Xie, S., 2023. Scalable diffusion models with transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision*,  4195-4205. [Link to GitHub Repo](https://github.com/facebookresearch/DiT).
    - Ludwig, J. and Mullainathan, S., 2024. Machine learning as a tool for hypothesis generation. *Quarterly Journal of Economics*, 139(2), 751-827.
    - Burnap, A., Hauser, J.R. and Timoshenko, A., 2023. Product aesthetic design: A machine learning augmentation. *Marketing Science*, 42(6), 1029-1056.
    - Dew, R., Ansari, A., & Toubia, O. (2022). Letting logos speak: Leveraging multiview representation learning for data-driven branding and logo design. *Marketing Science*, 41(2), 401-425.
    - Zhou, E., & Lee, D. (2024). Generative artificial intelligence, human creativity, and art. *PNAS nexus*, 3(3), pgae052.
    - Course Notes (Lecture 6) for CS294-158-SP24: Deep Unsupervised Learning, taught by Pieter Abbeel, Wilson Yan, Kevin Frans, Philipp Wu. [Link to CS294-158-SP24](https://sites.google.com/view/berkeley-cs294-158-sp24/home).
    - CVPR 2022 Tutorial: Denoising Diffusion-based Generative Modeling:
Foundations and Applications, by Karsten Kreis, Ruiqi Gao, and Arash Vahdat [Link to the Tutorial](https://cvpr2022-tutorial-diffusion-models.github.io/)
    - [Lilian Weng (OpenAI)'s Blog on Diffusion Models](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)
    - [Lilian Weng (OpenAI)'s Blog on Diffusion Models for Video Generation](https://lilianweng.github.io/posts/2024-04-12-diffusion-video/)
    - [Hugging Face Diffusers ðŸ¤— Library](https://huggingface.co/diffusers)